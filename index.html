<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Resume - Start Bootstrap Theme</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Yunting Yan</span>
                <span class="d-none d-lg-block"><img class="img-fluid" src="assets/img/photo.jpg" alt="..." /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#LAB1 Artemis">LAB1 Artemis</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#LAB2 IMU">LAB2 IMU</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#LAB3 ToF Sensors">LAB3 ToF Sensors</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#LAB4">LAB4 Motors & OL Control</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#LAB5">LAB5 PID Control</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#LAB6">LAB6 Orientation Control</a></li>

                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        Yunting
                        <span class="text-primary">Yan</span>
                    </h1>
                    <div class="subheading mb-5">
                        MAE5190 · Fast Robots · Spring2024 ·
                        <a href="mailto:name@email.com">yy2244@cornell.edu</a>
                    </div>
                    <p class="lead mb-5">Greetings! I'm Yunting, currently pursuing a MS. in Mechanical Engineering. Welcome to my webpage for Cornell MAE5190 Fast Robots. Here, you'll find detailed information on the 12 lab reports completed during the course.</p>
                    <div class="social-icons">
                        <a class="social-icon" href="#!"><i class="fab fa-linkedin-in"></i></a>
                        <a class="social-icon" href="#!"><i class="fab fa-github"></i></a>
                        <a class="social-icon" href="#!"><i class="fab fa-twitter"></i></a>
                        <a class="social-icon" href="#!"><i class="fab fa-facebook-f"></i></a>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- LAB1 Artemis -->
            <section class="resume-section" id="LAB1 Artemis">
                <div class="resume-section-content">
                    <h2 class="mb-5">Lab1 Artemis Board - Bluetooth</h2>
                    
                    
                    
                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Part1: Artemis Board</h3>
                            <div class="subheading mb-3">Objectives</div>
                            <p>In this section, we initialized the Artemis board and configured the Arduino Integrated Development Environment (IDE). Subsequently, we examined four illustrative examples by Artemis. Additionally, we formulated a comprehensive test case to validate the operational integrity of  the USB interface, temperature sensor, microphone, and LED.</p>
                            <div class="subheading mb-3">Artemis Example1: Blink LED</div>
                            <p>After installing Arduino IDE, we tested the LED on the board by running the "Blink" example and observed that the blue LED light was on and then off.</p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1ft1kP3U7_gnKxysoCdq-Rk1kIH-imt1i/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>
                            
                            <div class="subheading mb-3">Artemis Example2: Serial</div>
                            <p>In this example, we tested serial monitor output as shown below.</p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1snSuYuohTXUFi6heAjbIXKsk94wFp_-1/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>

                            <div class="subheading mb-3">Artemis Example3: Analog Read</div>
                            <p>
                                This example tested the digital temperature sensor on the Artemis board.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1DPFVweTwMCt40sUyxFnbYUW9t9-Ck5fE/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>

                            <div class="subheading mb-3">Artemis Example4: MICROPHONEOUTPUT</div>
                            <p>
                                The build in microphone was tested, the frequency of the sound received was printed to the serial monitor.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1mizJMngY0Vm23xU3A1eQYYtvWJ3VLMi4/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>

                            <div class="subheading mb-3">Tasks for MAE5190</div>
                            <p>
                                This experiment was to identify the musical "A," a sound that has a frequency of 1098.  Upon successful identification of the frequency by the microphone, a consequential action was triggered, causing the illumination of a blue LED. Conversely, in the absence of the identified frequency, the LED maintained an inactive state. The Arduin code is:
                            </p>
                            <pre>
                                <code>
                                    void setup(){
                                    Serial.begin(115200);
                                    printPDMConfig();
                                    // initialize digital pin LED_BUILTIN as an output.
                                    pinMode(LED_BUILTIN, OUTPUT);
                                    }

                                    void loop(){
                                    if (myPDM.available()){
                                        myPDM.getData(pdmDataBuffer, pdmDataBufferSize);
                                        uint32_t tmpF;
                                        tmpF = printLoudest(); //Example frequency detection function
                                        if (tmpF == 1098){
                                        digitalWrite(LED_BUILTIN, HIGH);
                                        }
                                        else{
                                        digitalWrite(LED_BUILTIN, LOW);
                                        }
                                    }
                                </code>
                            </pre>
                            <p>
                                The video below shows an example of the functionality of this code.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1S6mQHnx8dXLFyf-XmJT31ANrL7j3xkYJ/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">Jan 2024</span></div>
                    </div>

                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Part2: Bluetooth Connection</h3>
                            <div class="subheading mb-3">Objectives</div>
                            <p>In this section of the lab, we establish a protocol for the bi-directional exchange of data between the computer and the Artemis board. This process is facilitated through the utilization of the Bluetooth stack, employing Python for the PC side and Arduino for the Artemis board side.</p>
                            <div class="subheading mb-3">Setup</div>
                            <p>The following lab was done on a Windows 11 laptop with Anaconda3 and Python 3.11. Notice that Venv is not installed, and the intended connection between the Artemis board and the computer was successfully established.</p>
                            <p>To connect successfully, we first connect the board to the computer and upload ble_arduino.ino script provided in the lab to get the MAC address as shown in the figure below.</p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/macAdress.jpg" alt="..." />
                            </div>  
                            <p>Then in the "connection.yaml" file, change the MAC address to the one printed by the board. Then, a unique UUID was needed to connect to the right device. The id was generated using the code provided and overwritten the default UUID in the "connection.yaml" and "BLE_UUID_TEST_SERVICE" files. The finalized "connection.yaml" configuration is provided in the graph below for reference.</p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/connect.jpg" alt="..." />
                            </div>
                

                            <div class="subheading mb-3">Echo Test</div>
                            <p>To assess the connectivity between the Artemis board and the computer, a series of commands were executed for diagnostic purposes. The initial command employed for this purpose was the "ECHO" command. This command facilitated the transmission of a character string from the Python code to the Artemis board, which, in turn, reciprocated by transmitting the received phrase back to the Python code. This command was added to the Arduino code in ble_arduino.ino as shown below.</p>
                            <pre>
                            <code>
                                case ECHO:
                                    char char_arr[MAX_MSG_SIZE];
                                    // Extract the next value from the command string as a character array
                                    success = robot_cmd.get_next_value(char_arr);
                                    if (!success)
                                        return;
                                    tx_estring_value.clear();
                                    tx_estring_value.append("Robot says -> ");
                                    tx_estring_value.append(char_arr);
                                    tx_estring_value.append(" :)");
                                    tx_characteristic_string.writeValue(tx_estring_value.c_str());
                                    Serial.print("Robot says -> ");
                                    Serial.println(char_arr);
                                    Serial.println(" :)");
                                    return;
                                    break;
                            </code>
                            </pre>
                            <p> In Python sent the Echo command to Artemis, and see the reult shown below.</p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/echoPython.jpg" alt="..." />
                            </div>
                            

                            <div class="subheading mb-3">GET_TIME_MILLIS</div>
                            <p>The execution of the GET_TIME_MILLIS command encompasses the retrieval of the present time from the Artemis board. This process entails the utilization of the millis() function within the Arduino library to capture the current timestamp, subsequently converting it into a double data type. The resultant value is transmitted to Python as a string. The pertinent section of the Arduino code is shown below:</p>
                            <pre>
                                <code>
                                    case GET_TIME_MILLIS:
                                        char msg[20];
                                        tx_estring_value.clear();
                                        tx_estring_value.append("T:");
                                        sprintf(msg,"%lu",millis());
                                        tx_estring_value.append(msg);
                                        tx_characteristic_string.writeValue(tx_estring_value.c_str());
                                        Serial.println(tx_estring_value.c_str());
                                        break;
                                </code>
                            </pre>
                            <p>On the Python side, the following command is used. Notice that the return value is a timestamp not a real time.</p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/timePython.jpg" alt="..." />
                            </div>


                            <div class="subheading mb-3">Notification Handler</div>
                            <p>
                                In the foregoing examples, the proper reception of data necessitates the invocation of the "receive_string" method. However, in scenarios where the Artemis persistently transmits data at an indeterminate rate, relying solely on manual invocation may lead to suboptimal reception. Consequently, the implementation of a notification handler becomes imperative, ensuring the automatic retrieval and processing of transmitted data. The ensuing code snippet illustrates the structure of the handler function, along with the corresponding code for its invocation:
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/notificationPython.jpg" alt="..." />
                            </div>


                            <div class="subheading mb-3">Real-time Processing</div>
                            <p>
                                In this example, we call "GET_TIME_MILLIS" in Python through a loop. This function gets the current time in milliseconds and sends it to the computer to be received and processed by the notification handler as soon as a new timestamp is collected. Another way of implementing this real-time process is to create a command that loops in Arduino. The Python code to get and receive data (timestamp) is:
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/task4Python.jpg" alt="..." />
                            </div>
                            <p>
                                The "GET_TIME_MILLIS" command yields the recorded timestamp. By computing the temporal disparity between two consecutive timestamps, an estimation of the rate at which the Artemis accumulates and dispatches data can be derived. The empirical findings indicate an average speed of approximately 1.23 seconds for the complete process of data collection and transmission of a string.
                            </p>


                            <div class="subheading mb-3">Offline Processing</div>
                            <p>
                                As a counterpart to real-time processing, an alternative approach involves the storage of collected data on the Artemis, with subsequent transmission after the entirety of the data is collected. This is accomplished by establishing a global array capable of storing timestamps. Within the Arduino function, instead of executing real-time transmission, each timestamp is systematically inserted into the array. Furthermore, the introduction of a "SEND_TIME_DATA" command is implemented. This command iteratively traverses the array, transmitting each data point as a string to the computer for subsequent processing. The Arduino code is then enhanced with the inclusion of the following cases:
                            </p>
                            <pre>
                                <code>
                                    case GET_20_TIME_MILLIS:
                                      for (int x=0; x<20; x++){
                                        RecordTimes[x] = new char[20];
                                        sprintf(RecordTimes[x],"%lu",millis());
                                      }
                                      Serial.print("Time test done! [20]");
                                      break;
                          
                                    case SEND_TIME_DATA:
                                      for (int x=0; x<20; x++){
                                        tx_estring_value.clear();
                                        tx_estring_value.append(RecordTimes[x]);
                                        tx_characteristic_string.writeValue(tx_estring_value.c_str());
                                        Serial.println(tx_estring_value.c_str());
                                      }
                                      break;
                                </code>
                            </pre>
                            <p>The Python code is: </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/task5Python.jpg" alt="..." />
                            </div>
                            <p>
                                The results show that the average speed at the Artemis board is able to collect timestamp is 0.05ms, which is 10<sup>4</sup> faster than real-time processing.
                            </p>


                            <div class="subheading mb-3">Offline Processing of Temperature Data</div>
                            <p>
                                This section is similar to the former one but includes the use of digital temperature sensor. The Arduino codo is:
                            </p>
                            <pre>
                                <code>
                                    case GET_TIME_TEMP_START:
                                      for (int x=0; x<20; x++){
                                        RecordTemps[x] = new char[20];
                                        RecordTimes[x] = new char[20];
                                        sprintf(RecordTemps[x], "%lu", analogReadTemp());
                                        sprintf(RecordTimes[x],"%lu",millis());
                                      }
                                      Serial.print("Temps test done! [20]");
                                      break;
                                  
                                    case GET_TEMP_READINGS:
                                      for (int x=0; x<20; x++){
                                        tx_estring_value.clear();
                                        tx_estring_value.append("|Time:|");
                                        tx_estring_value.append(RecordTimes[x]);
                                        tx_estring_value.append("|Temp:|");
                                        tx_estring_value.append(RecordTemps[x]);
                                        tx_characteristic_string.writeValue(tx_estring_value.c_str());
                                        Serial.println(tx_estring_value.c_str());
                                      }
                                      break;
                                </code>
                            </pre>
                            <p>
                                The presented Python code and its corresponding results are delineated below. Upon examination of the outcome, it is evident that the Artemis expended an average time of 0.21 milliseconds for the data collection process. This duration is extended due to the inherent requirement of the device to retrieve data from the temperature sensor, thereby contributing to the observed elongation in the data collection time.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/task6Python.jpg" alt="..." />
                            </div>

                            <div class="subheading mb-3">Data Processing Discussion</div>
                            <p>
                                The advantage of real-time processing of data is that one can monitor the readings. Also, under certain conditions, the Artemis board might not have the capacity to process algorithms in time, and sending sensor data to the computer is needed. However, the communication between devices is slow. On the other hand, offline processing can have a high sample rate, but we do not know the data until finished collecting. The Artemis board has 384 kB of RAM. Assuming all memory can be used to store characters and one character causes 1 byte, we can store 393,216 characters. 
                            </p>


                            <div class="subheading mb-3">Effective Data Rate And Overhead</div>
                            <p>
                                This task compares the data rate for5 bytes and 120 bytes reply from the Artemis. Python code used is shown below:
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/task7Python.jpg" alt="..." />
                            </div>
                            <p>
                                The data rate for 5 bytes reply is 16.7 bytes/s, and data rate for 120 bytes is 477.5 bytes/s. Thus, the bigger message size leads to a bigger data rate, and larger message reduce the overhead.
                            </p>

                            <div class="subheading mb-3">Reliability</div>
                            <p>
                                When carried out previous sections, reliability issue is observed. The computer cannot read all messages if the Artemis is publishing short messages at very high rate. To address this problem, a delay in sending message is needed, or we can use the offline processing method.
                            </p>

                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Lab Discussion</h3>
                            <p>
                                In this lab, we established a bluethooth connection between the computer and the Artemis board and explore the limitation of data rate in bluetooth communication. 
                            </p>
                        </div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />


            <!-- LAB2-->
            <section class="resume-section" id="LAB2 IMU">
                <div class="resume-section-content">
                    <h2 class="mb-5">LAB2 IMU</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Objectives</h3>
                            <p>
                                This lab integrated an  Inertial Measurement Unit (IMU) onto the Artemis board to sense the robot's orientation and acceleration. Two methods for measuring orientation, using a gyroscope and accelerometer, were introduced and their advantages and drawbacks analyzed. Finally, the IMU was mounted on the RC robot for testing.
                            </p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">Feb 2024</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">IMU Setup</h3>
                            <div class="subheading mb-3">IMU Connection</div>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab2IMU.jpg" alt="..." />
                            </div>

                            <div class="subheading mb-3">IMU Readings</div>
                            <p>
                                After connecting the IMU to the Artemis board, we tested the connection by running the example provided by the library to read sensor readings as shown below.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1o8ayQW6IfAbYgrF8Gtw5vV9kEoR_CEoV/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>

                            <div class="subheading mb-3">AD0_VAL</div>
                            <p>
                                "AD0_VAL" represents the value of the last bit of the I2C address used to communicate with the ICM-20948 IMU sensor.
                            </p>

                            <div class="subheading mb-3">Acceleration and Gyroscope Data Discussion</div>
                            <p>
                                When contrasting the accelerometer and gyroscope data, it is observed that when the IMU is positioned on a level surface, the accelerometer demonstrates fluctuations within the range of &plusmn 15 ms/s&sup2, while the gyroscope fluctuates between &plusmn 1 degree per second.
                            </p>
                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">ACCELEROMETER</h3>
                            <p>
                                The accelerometer integrated within the Inertial Measurement Unit (IMU) captures acceleration data in millimeters per second squared (mm/s²). Pitch and roll angles can be derived from the acceleration components along the x, y, and z axes, denoted as ax, ay, and az respectively, as depicted in Eq1. During the implementation of the function, the atan2 function is employed to determine the quadrant.
                            </p>
                            <div style="text-align: center;">
                                <p>	Theta = arctan(<span style="white-space: nowrap;"><span style="vertical-align: super;">ax</span> / <span style="vertical-align: sub;">az</span></span>)</p>
                                <p>	Phi = arctan(<span style="white-space: nowrap;"><span style="vertical-align: super;">ay</span> / <span style="vertical-align: sub;">az</span></span>)</p>                               
                            </div>
                            <p>
                                Utilizing the aforementioned equations, the pitch and roll measurements obtained at {90,-90} are depicted below. Observing the graphical representation, it becomes evident that when the pitch is set to 90 degrees, the roll measurement exhibits greater fluctuation compared to the scenario where the IMU is positioned horizontally. Additionally, an observation is made that at a pitch of 90 degrees and a roll of -90 degrees, the fluctuation in roll surpasses that of pitch.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/LAB2acc.jpg" alt="..." />
                            </div>
                            <p>
                                The Fourier transformation of pitch and roll is shown below. The signal for roll is noisier than that of pitch. To limit the noise, we can use a low pass filter. A mean filter can help to reduce the noise and is implemented.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/LAB2accftRAW.jpg" alt="..." />
                            </div>
                            <p>
                                The filtered signal is shown below.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/LAB2FT.jpg" alt="..." />
                            </div>
                        </div>
                    </div>


                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">gyroscope</h3>
                            <p>
                                To mitigate the noise present in the pitch and roll calculations derived from accelerometer data and to capture yaw, it was imperative to incorporate gyroscope readings. Analysis of the accompanying graphs reveals a gradual drift in the gyroscope data over time, attributed to the integration of raw data. Despite the gyroscope being less noisy than the accelerometer, integration poses a significant risk of introducing substantial errors in robotic applications. Consequently, a synergistic approach involving the fusion of gyroscope and accelerometer data was pursued to establish a sensor system characterized by enhanced accuracy and reduced noise levels.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/LAB2GYR1.jpg" alt="..." />
                            </div>
                            <p>
                                The following code implemented a complimentary filter.
                            </p>
                            <pre>
                                <code>
                                    // complimentary filter
                                    pitchAcc2 = atan2(sensor->accX(),sensor->accZ())*57.2958*1.02;
                                    rollAcc2 = atan2(sensor->accY(),sensor->accZ())*57.2958*1.02;
                                    pitchGyr2 = pitchAcc2*(CompFilterAlpha) + (pitchGyr2 + (sensor->gyrY())*gryStep*0.001)*(1-CompFilterAlpha);
                                    rollGyr2 = rollAcc2*(CompFilterAlpha) + (rollGyr2 + (sensor->gyrX())*gryStep*0.001)*(1-CompFilterAlpha);
                                    yawGyr2 = yawGyr2*(CompFilterAlpha) + (yawGyr2 + (sensor->gyrZ())*gryStep*0.001)*(1-CompFilterAlpha);
                                </code>
                            </pre>
                            <p>
                                The filter signal is shown below.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/LAB3GYRFILTER.jpg" alt="..." />
                            </div>
                        </div>
                    </div>


                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">SAMPLE DATA</h3>
                            <p>
                                Delays introduced for debugging purposes were eliminated to assess the sampling rate of the Inertial Measurement Unit (IMU). Time stamps, accelerometer data, and gyroscope data were stored in memory for subsequent transmission after data collection. The average sampling interval was determined to be 3 milliseconds. Data was organized into separate float arrays and subsequently transmitted to the computer as a concatenated array. The Arduino code implementing this functionality is provided below.   
                            </p>
                            <pre>
                                <code>
                                    case getData:
                                        for (int x=0; x<1500; x++){
                                            if (myICM.dataReady()){
                                            myICM.getAGMT();
                                            printScaledAGMT(&myICM); 
                                            }
                                            else{
                                            SERIAL_PORT.println("Waiting for data");
                                            delay(500);
                                            }
                                        }  
                                        break;
                                    case sendData:
                                    for (int y=0; y<1500; y++){
                                        tx_estring_value.clear();
                                        tx_estring_value.append("|accpitch|");
                                        tx_estring_value.append(accpitch[y]);
                                        tx_estring_value.append("|accroll|");
                                        tx_estring_value.append(accroll[y]);
                                        tx_estring_value.append("|gyrpitch|");
                                        tx_estring_value.append(gyrpitch[y]);
                                        tx_estring_value.append("|gyrroll|");
                                        tx_estring_value.append(gyrroll[y]);
                                        tx_estring_value.append("|gyryaw|");
                                        tx_estring_value.append(gyryaw[y]);
                                        tx_estring_value.append("|time|");
                                        tx_estring_value.append(timeData[y]);           
                                        tx_characteristic_string.writeValue(tx_estring_value.c_str());
                                    }
                                    break;
                                    // in printScaledAGMT, add the following
                                    if (myICM.dataReady()){
                                        if (index1 < 1500){
                                          accpitch[index1] = pitch;
                                          accroll[index1] = roll;
                                          gyrpitch[index1] = pitchGyr;
                                          gyrroll[index1] = rollGyr;
                                          gyryaw[index1] = yawGyr;
                                          timeData[index1] = (float)millis();
                                          index1 ++;
                                        }
                                      }
                                </code>
                            </pre>
                            <p>
                                The result is shown below. In the test, data is collected for approximately 6s.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/LAB2sampledata.jpg" alt="..." />
                            </div>
                            <p>
                                In this exercise, opting to store data as arrays of floats emerges as an efficient solution. This choice strikes a balance between precision, allowing for accurate representation of fractional values, and efficiency in storing multiple readings within a single data structure. While integers consume less memory, they sacrifice precision, potentially compromising the fidelity of the data. On the other hand, arrays of characters, though versatile, are not as storage-efficient as floats, making them less favorable for this task.
                            </p>
                        </div>
                    </div>



                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">RECORD A STUNT</h3>
                            <p>
                                The following video demonstrates the robot being teleport by the controller.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1XxEOaONcXwlwuIHLWB1zM5HFeXMHh9CN/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>

                        </div>
                    </div>
                    </div>
                </div>
            </section>
           
            <hr class="m-0" />
            <!-- LAB3 Time of Flight Sensors-->
            <section class="resume-section" id="LAB3 ToF Sensors">
                <div class="resume-section-content">
                    <h2 class="mb-5">LAB3 Time of Flight Sensors</h2>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Objectives</h3>
                            <p>
                                The objective of this laboratory exercise is to enhance the functionality of the robot by integrating Time of Flight (ToF) sensors. These sensors provide the robot with the capability to measure its distance from objects in its surrounding environment.
                            </p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">Feb 2024</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Pre-LAB</h3>
                            <p>
                                According to the  VL53L1X datasheet, the default address is 0x52. By executing the "Wire_I2C" example, the address of the ToF sensor is 0x29.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab3Addr.jpg" alt="..." />
                            </div>
                            <p>
                                In our proposal, we present two prospective configurations for sensor placement. The first configuration involves the installation of sensors both at the front and rear ends of the robot. This arrangement facilitates environmental perception by necessitating only a 90-degree turn, as opposed to other configurations that mandate a 180-degree rotation for comprehensive environmental sensing. However, it is noteworthy that in scenarios involving robot teleportation, this setup renders the robot incapable of detecting obstacles situated on its sides. The second configuration entails positioning one sensor at the front of the robot and another on its lateral side. This arrangement augments the robot's capability to sense its surroundings, particularly enabling it to detect objects situated to its side.
                            </p>
                            <p>
                                A sketch of wiring diagram is shown below.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/LAB3schema.jpg" alt="..." />
                            </div>
                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">ToF Connection</h3>
                            <p>
                                The following image shows an example of connecting a ToF sensor to the Artemis board. The test results is shown in picture above, and the address is 0x29.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab3wiring1.jpg" alt="..." />
                            </div>
                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">ToF Sensor Modes</h3>
                            <p>
                                The ToF sensor offers three distinct operational modes: short, medium, and long. The short-distance mode is characterized by heightened precision and represents a viable candidate for establishing a baseline mechanism for promptly halting the robot in emergent scenarios to prevent collisions with obstacles. Given the absence of additional long-distance sensors onboard, the long-distance mode is the preferred choice. Despite the presence of increased sensor noise in this mode, it boasts a detection range spanning 4 meters. This extended range ensures that the swiftly moving robot can promptly discern potential obstacles and react on time. The efficacy of the long-distance mode was evaluated with the results documented below.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab3TOF_test.jpg" alt="..." />
                            </div>
                        </div>
                    </div>




                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Multi-ToF Sensors</h3>
                            <p>
                                In this section, we address the challenge posed by connecting two Time-of-Flight (ToF) sensors to the Artemis board. Due to the default configuration where both sensors share the same address, a conflict arises, impeding the functionality of one sensor by blocking the communication channel of the other. To circumvent this issue, we employ a solution wherein we temporarily deactivate one sensor by connecting its "XSHUT" pin to pin A8 on the Artemis board. Subsequently, we utilize the provided code to adjust the address of the remaining sensor, thereby resolving the address conflict and ensuring the proper operation of both sensors simultaneously.
                            </p>
                            <pre>
                                <code>
                                    //Add this in global scale
                                    //Optional interrupt and shutdown pins.
                                    #define SHUTDOWN_PIN_1 8
                                    #define INTERRUPT_PIN_1 3
                                    #define SHUTDOWN_PIN_2 6
                                    #define INTERRUPT_PIN_2 4
                                    //SFEVL53L1X distanceSensor1;
                                    //Uncomment the following line to use the optional shutdown and interrupt pins.
                                    SFEVL53L1X distanceSensor1(Wire, SHUTDOWN_PIN_1, INTERRUPT_PIN_1);
                                    SFEVL53L1X distanceSensor2(Wire, SHUTDOWN_PIN_2, INTERRUPT_PIN_2);

                                    //Add this to setup()
                                    //Shut down sensor 2
                                    distanceSensor1.sensorOff();
                                    //Change address of sensor 1 from default to NEW_ADDRESS
                                    distanceSensor2.setI2CAddress(0x32);
                                    Serial.print("Sensor 2 address changed to 0x");
                                    Serial.println(distanceSensor2.getI2CAddress(), HEX);
                                    distanceSensor1.sensorOn();
                                </code>
                            </pre>
                            <p>
                                Now we can read from both sensors as shown below.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab3TwoSensorsReading.jpg" alt="..." />
                            </div>
                        </div>
                    </div>


                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Tof sensor speed</h3>
                            <p>
                                The Time-of-Flight sensors exhibit a slower data acquisition speed compared to the looping speed of the Artemis board. Evaluation of clock timing and sensor data availability indicates an average acquisition time of 90 milliseconds, contrasting with the Artemis board's 2-millisecond iteration capability. This discrepancy stems from factors such as the sensors' start-stop ranging process for each iteration and their operation in long-range mode.
                            </p>
                            <pre>
                                <code>
                                    distanceSensor2.startRanging(); //Write configuration bytes to initiate measurement
                                    while (!distanceSensor2.checkForDataReady())
                                    {
                                      Serial.println(millis());
                                    }
                                    int distance = distanceSensor2.getDistance(); //Get the result of the measurement from the sensor
                                    distanceSensor2.clearInterrupt();
                                    distanceSensor2.stopRanging();
                                    // same for the other sensor
                                </code>
                            </pre>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/LAB3SensorSpeed.jpg" alt="..." />
                            </div>
                        </div>
                    </div>


                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Bluetooth transmission</h3>
                            <p>
                                Using similar methods in Lab 2, the distance from both sensors was sent to the computer via Bluetooth.  The notification handle is shown below.
                            </p>
                            <pre>
                                <code>
                                    def notificationHandler(uuidStr, bytesArray):
                                        global tofData1,timeData,tofData2
                                        decoded_data = bytesArray.decode('utf-8')
                                        split_data = decoded_data.split("|")
                                        tofData1.append(split_data[4])
                                        timeData.append(split_data[2])
                                        tofData2.append(split_data[5])
                                        return
                                    timeData = []
                                    tofData1 = []
                                    tofData2 = []
                                    ble.start_notify(ble.uuid['RX_STRING'], notificationHandler)
                                    ble.send_command(CMD.getData,"")
                                    time.sleep(5)
                                    ble.send_command(CMD.sendData,"")
                                    time.sleep(10)
                                    ble.stop_notify(ble.uuid['RX_STRING'])
                                </code>
                            </pre>
                            <p>
                                The sample data for both sensors is shown below, and the x-axis is time in ms. 
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/LAB3ble_twosensor.jpg" alt="..." />
                            </div>
                        </div>
                    </div>

 

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Discussion on infrared transmission based sensors</h3>
                            <p>
                                There are three common types of IR sensors, including amplitude-based, triangulation-based, and time-of-flight (ToF) IR sensors. Amplitude-based sensors measure the intensity of IR radiation reflected or emitted by objects and provide solutions for proximity sensing with fast response times but are limited in range and accuracy. Triangulation-based sensors calculate the distance to an object by measuring the angle of reflected IR light and offer higher accuracy and longer ranges compared to amplitude-based sensors. Time-of-flight sensors measure the time taken for IR light to travel to the object and back to determine distance and are more accurate in measuring longer distances.
                            </p>
                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Sensitivity of sensors to environments</h3>
                            <p>
                                Since the time of flight sensor measures the time of the signal before it returns. It is mostly insensitive to colors, textures, and ambient light compared to other IR sensors mentioned above. However, high levels of ambient light might interfere with the sensors' ability to detect, light-colored surfaces may reflect more light, and highly irregular textures may affect detection.
                            </p>
                        </div>
                    </div>

                </div>
            </section>





            <hr class="m-0" />
            <!-- LAB4 Motors and Open Loop Control-->
            <section class="resume-section" id="LAB4">
                <div class="resume-section-content">
                    <h2 class="mb-5">LAB4 Motors and Open Loop Control</h2>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">senor implementation on the robot</h3>
                            <p>
                                Given the dual motor setup, two motor drivers are used. The Artemis can only supply up to 3V voltage and is not capable of powering the motor at 3.7V. The motor drivers took two PWMs as input and connected to an external battery. A schematic of implementing the sensors on the robot is shown below.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab4car.jpg" alt="..." />
                            </div>
                            <p>
                                The following graph shows the connection between motors, motor drivers, Artemis, and the battery. One motor is connected to pins 7 and 9 and the other to pins 11 and 12. These pins are chosen due to their PWM capabilities.s
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab4schema.jpg" alt="..." />
                            </div>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">Feb 2024</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">battery</h3>
                            <p> 
                                The laboratory kit includes two batteries: one with a capacity of 650mAh and another with 850mAh. To mitigate interference between the motors and the Artemis microcontroller, separate batteries will be dedicated to each component. Given the higher power consumption of the motors compared to the Artemis, the 850mAh battery will be allocated to power the motors, while the 650mAh battery will be utilized to supply power to the Artemis microcontroller.
                            </p>
                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">TESTING THE DUAL MOTOR DRIVER</h3>
                            <p>
                                The dual motor driver was tested using a 3.7V power supply in lieu of the motor, with input and output signals measured using an oscilloscope. See the connection below.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab4_external_battery.jpg" alt="..." />
                            </div>
                            <p>
                                The power supply was set to the same voltage output as the 850mAh battery, 3.7V, to simulate the voltage readings. The code used to drive the motors is shown below.
                            </p>
                            <pre>
                                <code>
                                    void setup() {
                                        Serial.begin(115200);
                                        analogWrite(7, 0);
                                        analogWrite(9, 0);
                                        analogWrite(12, 0);
                                        analogWrite(11, 0);
                                      }
                                      
                                      void loop() {
                                        Serial.println("Start");
                                        analogWrite(11, 0);
                                        analogWrite(12, 100);//right
                                        //analogWrite(9, 0);
                                        //analogWrite(7, 255);
                                        delay(4000);
                                        
                                        analogWrite(11, 0);
                                        analogWrite(12, 0);
                                        analogWrite(9, 0);
                                        analogWrite(7, 0);
                                        delay(4000);
                                        
                                        analogWrite(11, 100);
                                        analogWrite(12, 0);
                                        delay(4000);
                                      }
                                      
                                </code>
                            </pre>
                            <p>
                                The reading of the oscilloscope is shown below.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab4osci.jpg" alt="..." />
                            </div>
                            <p>
                                The following video was taken to demonstrate control of the motors. The wheels were programmed to spin in either direction for 4s each.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/11_Fm9tWEjc0WoRE1HL4oMhbGsvTH8oUJ/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>

                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">both wheels spinning</h3>
                            <p>
                                The following video shows an example of both wheels on the two sides spinning on batteries.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1XGj900W0vWt5S1VjRNpyLZ-qT45iSxxt/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>
                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Lower limit PWM value</h3>
                            <p>
                                The motors were assessed to determine their operational range, focusing initially on the lower threshold. By iteratively adjusting the PWM value until motion initiation was observed from a standstill position, the lower limit of the robotic system's locomotion was identified. Notably, experimentation revealed this threshold to be contingent upon the surface characteristics. Specifically, on a flat and polished wooden surface, the respective lower limit values for the left and right wheels were determined to be 90 and 85. Conversely, when evaluated on a PVC floor, these values were observed to be 105 and 95 for the left and right wheels, respectively.
                            </p>
                        </div>
                    </div>




                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Calibration and Open Loop Control</h3>
                            <p>
                                From the section above, it is clear that the two motors have different thresholds. Therefore, calibration is needed to drive the car in a straight line. The calibration process was done by adjusting the analog output value and observing the car driving on the ground. The empirical calibration is to have the left motor's output greater than that of the right by 10 to 15 in absolute value.
                            </p>
                            <pre>
                                <code>
                                    // right
                                    analogWrite(11, 0);
                                    analogWrite(12, 100);
                                    // left
                                    analogWrite(9, 0);
                                    analogWrite(7, 115);
                                </code>
                            </pre>
                            <p>
                                The open loop control video is shown below. The distance traveled in the lab is about 2.5m, and the car is driving in approximately a straight line.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1aDbZnU6MkkImQqf-dklYGwjVCh3KxB39/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>
                            <p>
                                The video below shows the car drive in straight line and make a turn.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/16YU0Yqziljqg4P2FgsAPlplc9b4wW9cR/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>
                        </div>
                    </div>


                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">ANALOGWRITE SPEED AND LOWER LIMIT VALUE</h3>
                            <p>
                                The analogWrite function on the Artemis operates with a time step of 3ms, resulting in a frequency of approximately 333Hz, sufficiently rapid for our robotic application, facilitating swift changes in direction. Manual configuration of timers could enhance PWM signal stability, particularly as the current time step exhibits fluctuations. Faster readings enable the robot to better sustain the directed PWM signal.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab4analogTime.jpg" alt="..." />
                            </div>
                            <p>
                                The lowest PWM value while the robot was in motion was tested to be 30 for the right motor and 42 for the left motor.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1TDe-ADC-UoEJotvzAIu7I_lCveVtr2B_/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            






            <hr class="m-0" />
            <!-- LAB5 PID Control-->
            <section class="resume-section" id="LAB5">
                <div class="resume-section-content">
                    <h2 class="mb-5">LAB5 PID Control</h2>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Pre-LAB</h3>
                            <p>
                                In light of prior laboratory experiments, it has been observed that Bluetooth-based data transmission exhibits latency, but a rapid iteration rate is needed for the control loop. To address this, the timestamp, time of flight sensor data, and motor driver output data will be stored within the memory of the Artemis microcontroller. Subsequent to the vehicle reaching its designated endpoint, the accumulated data will be transmitted to the computer. Timestamps will be stored in an array format comprising characters, while other data will be stored in arrays of floating-point numbers, as exemplified below. Also, the space can save data upto 5s approximately.
                            </p>
                            <pre>
                                <code>
                                    char* RecordTimes[1000];
                                    int RecordToF1[1000];
                                    int RecordToF2[1000];
                                    int RecordV[1000];
                                </code>
                            </pre>
                            <p>
                                On the python side, a notificationHandler is created as outlined below.
                            </p>
                            <pre>
                                <code>
                                    def notificationHandler(uuidStr, bytesArray):
                                        global tofData1,timeData,tofData2,velocity
                                        decoded_data = bytesArray.decode('utf-8')
                                        split_data = decoded_data.split("|")
                                        timeData.append(split_data[2])
                                        tofData1.append(split_data[4])
                                        tofData2.append(split_data[5])
                                        velocity.append(split_data[7])
                                        return
                                    velocity = []
                                    timeData = []
                                    tofData1 = []
                                    tofData2 = []
                                    ble.start_notify(ble.uuid['RX_STRING'], notificationHandler)
                                </code>
                            </pre>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">Feb 2024</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">controller</h3>
                            <p> 
                                PID control is utilized for its capacity to provide precise and stable control, crucial for accurately maneuvering and halting the vehicle at a specified position (at 304mm from the wall). The proportional component promptly responds to deviations from the desired trajectory. The integral component, accumulating over time, mitigates persistent errors in achieving the setpoint. Moreover, the derivative component forecasts impending changes, attenuating oscillations induced by integral action while fortifying system stability. Empirically determined gains, set at Kp=0.02, Ki=0.0002, and Kd=0.002, result from iterative adjustments following individual testing of each parameter and subsequent synthesis to optimize control performance.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab5PIDBlock.png" alt="..." />
                                <figcaption>Source: Improved Electrical Discharge Machine (EDM) Servomechanism Controller for Machining Micro Pits.</figcaption>
                            </div>
                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Range/Sampling time</h3>
                            <p> 
                                Given the task's requirement for the vehicle to initiate at a distance of 2-4 meters from the wall, ToF sensors are configured to long-range mode. While ideally, a swift sampling time is preferred, shortening it considerably compromises sensor accuracy. To maintain a balance between accuracy and sampling efficiency, the default setting is retained, albeit passed through a mean filter with a kernel size of two. This approach mitigates abrupt variations while preserving an acceptable compromise between precision and sampling frequency. The code to filter data is shown below:
                            </p>
                            <pre>
                                <code>
                                    if (distanceSensor1.checkForDataReady()){
                                        distance1 = (distanceSensor1.getDistance()+lastDistance1)/2; //Get the result of the measurement from the sensor
                                        distanceSensor1.clearInterrupt();
                                        distanceSensor1.stopRanging();
                                    }
                                    else{
                                        distance1 = distance1 + (distance1-lastDistance1)/dtDistance;
                                    }
                                </code>
                            </pre>
                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Wall Reaching Task</h3>
                            <p>
                                The following code implemented the PID controller. The PIDControl function calculate the raw motor input and cap the upper and lower bound of the integrator. The ToFSenseAndDrive functoin cap the maximum possible motor input and drive the motors.
                            </p>
                            <pre>
                                <code>
                                    float PIDControl(float kp, float ki, float kd, float distance){
                                        float errorCurrent = distance - stopDistance;
                                        dt = millis() - lastTime;
                                        lastTime = millis();
                                        if (distance < 150){
                                          return 0;
                                        }
                                        // P control
                                        float P = kp*errorCurrent;
                                        // I control
                                        integraterError += (errorCurrent*dt/10);
                                        if (integraterError > 10000){
                                          integraterError = 10000;
                                        }
                                        else if (integraterError < -10000){
                                          integraterError = -10000;
                                        }
                                        float I = ki*integraterError;
                                        Serial.println(integraterError);
                                        if (I > 150){
                                          I = 150;
                                        }
                                        else if (I < -150){
                                          I = -150;
                                        }
                                        // D control
                                        float D = kd*(errorCurrent - errorLast)/dt;
                                        errorLast = errorCurrent;
                                        float speed = P+I+D;
                                        if ((speed>30)&&(speed<45)){
                                          speed = 45;
                                        }
                                        return speed;
                                      }
                                      
                                      void stopCar(){
                                        analogWrite(11, 0);
                                        analogWrite(12, 0);
                                        analogWrite(7, 0);
                                        analogWrite(9, 0);
                                      }
                                      
                                      int ToFSenseAndDrive(float distance1,float distance2,float dt,int sensor){
                                        float v;
                                        if (sensor == 1){
                                          v = PIDControl(kp,ki,kd,distance1);
                                          if (int(v) >= 240){
                                            v = 240;
                                          }
                                          else if (int(v) <= -240){
                                            v = -240;
                                          }
                                          analogWrite(11, 0);
                                          analogWrite(12, int(v)); //right
                                          analogWrite(7, int(v*1.2+20)); //left
                                          analogWrite(9, 0);
                                        }
                                        return int(v);
                                      }                                    
                                </code>
                            </pre>
                            <p>
                                The following video demonstrate the driving task. The car starts at around 2.5 meters from the wall and stop at 300mm from the wall.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1i_L60Xf2-ARftGfiKuUoZUldmLE2Q5vg/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>
                            <p>
                                This control algorithm accommodates varying iteration rates within the PID controller and Time-of-Flight (ToF) sensors. In the absence of new data, distance prediction relies on observed distances via linear extrapolation, as previously detailed in the provided code sections. Additionally, an empirical determination establishes a motor input threshold, revealing that the car halts when the input falls below 40. Consequently, a PID output range of 30 to 45 prompts the controller to initiate a very slow movement, with a defined minimum speed set at 45. While generally effective in driving and stopping the car, a minor discrepancy of 6mm from the precise position persists..
                            </p>
                            <p>
                                The following figures demonstrate the distance to the wall over time, and the motor input over time.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab5TOF_with_cap_interpolation.jpg" alt="..." />
                                <img class="img-fluid" src="assets/img/lab5speed_cap_interpolation.jpg" alt="..." />
                            </div>
                            <p>
                                The front ToF graph indicates that the car initiates at 2.5m and halts approximately 288mm from the wall. Although this position is not precisely aligned with the intended stop point, it is deemed reasonably accurate considering inherent motor imprecision and substantial wheel friction. Concurrently, the motor input graph exhibits an initial erroneous point, swiftly rectified to ensure negligible impact on the car's trajectory. Furthermore, the car's speed diminishes gradually as proximity to the wall decreases, reflecting an adaptive response to the changing distance.
                            </p>
                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Wind-up implementation</h3>
                            <p>
                                The following video shows the car running with the same control gains but has no wind-up implementation.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1KMoCxyLQKdLHq3HraltTS_Im5Pi6vzcP/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>
                            <p>
                                The wind-up phenomenon is discernible from the video, wherein the integrator persistently accumulates errors, consequently extending the system's recovery duration. Despite the car's proximity to the wall, the accumulated error remains unresolved, thereby exerting excessive force as the integrator continues to operate at full capacity.
                            </p>
                        </div>
                    </div>
                </div>
            </section>



            <hr class="m-0" />
            <!-- LAB6 Orientation Control-->
            <section class="resume-section" id="LAB6">
                <div class="resume-section-content">
                    <h2 class="mb-5">LAB6 Orientation Control</h2>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Pre-LAB</h3>
                            <p>
                                To measure the car's basic parameters while operating untethered. Bluetooth connection is established between the computer and the Artemis. However, from prior laboratory experiments, it has been observed that Bluetooth-based data transmission exhibits latency. Sending real-time data through Bluetooth slows down the control loop and sensing rate inevitably. To address this, the timestamp, gyroscope data, and motor driver output data will be stored within the memory of the Artemis microcontroller. After the car achieves the task, the "sendData" command will be sent from the computer to retrieve stored data from the Artemis. The code structure is depicted below.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab6codeStruct.jpg" alt="..." />
                            </div>
                            <p>
                                On the python side, a notificationHandler is created as outlined below.
                            </p>
                            <pre>
                                <code>
                                def notificationHandler(uuidStr, bytesArray):
                                    global tofData1,timeData,tofData2,velocity
                                    decoded_data = bytesArray.decode('utf-8')
                                    split_data = decoded_data.split("|")
                                    timeData.append(split_data[2])
                                    gyrData.append(split_data[4])
                                    velocity.append(split_data[6])
                                    return
                                velocity = []
                                timeData = []
                                gyrData = []
                                ble.start_notify(ble.uuid['RX_STRING'], notificationHandler)
                                ble.send_command(CMD.setPID,"0.02|0.00002|0.002")
                                ble.send_command(CMD.getData,"1")
                                </code>
                            </pre>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">March 2024</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">controller</h3>
                            <div class="subheading mb-3">PID discussion</div>
                            <p> 
                                PID control is employed for precise and stable control, essential for accurately guiding and stopping vehicles at predefined orientations. The proportional component responds to deviations from the intended orientation. Meanwhile, the integral component, accumulating errors over time, rectifies persistent deviations from the setpoint, enhancing precision. Additionally, the derivative component anticipates changes in the system, thereby mitigating oscillations caused by integral action and bolstering overall system stability. The empirically determined gains, set at Kp=2, Ki=0.02, and Kd=0.05, result from iterative adjustments following individual testing of each parameter and subsequent synthesis to optimize control performance. Increasing the proportional gain (Kp) reduces the rise time and the steady state error, yet it cannot close the error completely. Elevating the integral gain (Ki) reduces steady-state error but can prolong the settling time and provoke overshoot if excessively amplified. Likewise, elevating the derivative gain (Kd) tends to attenuate overshoot and oscillations but can amplify noise sensitivity and destabilize the system if set too high.
                            </p>
                            <div class="subheading mb-3">PID Input Signal</div>
                            <p>
                                The gyroscope data is integrated over time to obtain the yaw of the car as shown below.
                            </p>
                            <pre>
                                <code>
                                    if (initGyr){
                                        yawGyr = (sensor->gyrZ())*dtIMU*0.001;
                                        desiredAngle = yawGyr;
                                        initGyr = false;
                                    }
                                    else{
                                        yawGyr += (sensor->gyrZ())*dtIMU*0.001;
                                    }
                                </code>
                            </pre>
                            <p>
                                This integration method might lead to the yaw measurement drifting over time since the integrator is cumulating errors. To mitigate this problem, we could introduce a low pass filter, such as a mean filter, before integration. However, in this lab, I observed that the drift is relatively small as the car is operating in a short period. Additionally, if we are calculating the pitch and roll, we should introduce a complimentary filter. However, when calculating yaw, this method is not feasible since there is no way to find yaw from the accelerometer.
                            </p>
                            <p>
                                Gyroscopes exhibit biases, manifesting as constant offsets in their output, even in the absence of rotation. To mitigate this, an initial gyroscope reading is recorded upon startup. Subsequently, this recorded bias is subtracted from all subsequent readings to enhance accuracy.
                            </p>
                            <p>
                                As per the IMU datasheet, a maximum rotational output limit of 250 degrees per second (dps) is specified. Consequently, rapid turns exceeding this threshold may result in inaccurate yaw measurements. This is mostly enough for this lab. On the other hand, to circumvent this limitation, adjusting the cap to 500 dps could mitigate such inaccuracies.
                            </p>
                            <div class="subheading mb-3">Derivative Control</div>
                            <p>
                                To compute the derivative of the control output concerning yaw measurement, it is imperative to differentiate the yaw signal, obtained through the integration of gyroscope readings. This process may entail amplification of high-frequency noise inherent in the signal, potentially exacerbating gyroscope noise. Nonetheless, derivative computation is straightforward to execute, and I have not encountered notable discrepancies as a consequence. Should such issues arise, the adoption of a low-pass filter to mitigate high-frequency noise stemming from the derivative term would be advisable.
                            </p>
                            


                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Range/Sampling time</h3>
                            <p> 
                                When running the gyroscope, the timestamp for which data is being updated is recorded and shown below. The average sampling rate is 50 samples per second. Though we desired a high sample rate, this is enough for the orientation task.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab6samplerate.jpg" alt="..." />
                            </div>
                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Orientation Control</h3>
                            <p>
                                This task encompasses two phases. The user can optionally transmit a command to set the vehicle's orientation with the specified goal, and the car will move to the designated orientation. Subsequently, the vehicle readjusts its orientation to realign with the goal following any disturbances encountered. If no goal is set by the user, the initial angle is the goal.
                            </p>
                            <div style="text-align: center;">
                                <iframe src="https://drive.google.com/file/d/1-cIOI93k_8NCFPjalUaO4r98yDvbxEfW/preview" width="640" height="480" allow="autoplay"></iframe>
                            </div>
                            <p>
                                In pursuit of this objective, various combinations of PID gains were experimentally evaluated. The initial trial employed the PID values utilized in the preceding laboratory session, namely kp=0.2, ki=0.0002, and kd=0.02. Subsequent analysis presents the evolution of the car's angle and the corresponding Pulse Width Modulation (PWM) output over time.
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab6yaw_trail1.jpg" alt="..." />
                                <img class="img-fluid" src="assets/img/lab6velocity_trail1.jpg" alt="..." />
                            </div>
                            <p>
                                From the graph above, the PWM signal is too weak to drive the wheels and the car does not move. Therefore, I increased the gains such that kp=1, ki=0.02, and kd=0.2. The angle and PWM signal over time is shown below. 
                            </p>
                            <div style="text-align: center;">
                                <img class="img-fluid" src="assets/img/lab6_yaw_trail2.jpg" alt="..." />
                                <img class="img-fluid" src="assets/img/lab6_velocity_trail2.jpg" alt="..." />
                            </div>
                            <p>
                                From the orientation graph, when the perturbation is small, the car is capable of returning to the desired angle with some steady state error. However, when the perturbation is big (at 60000ms), the PID controller is oscillatory. At this point, not only the settling time is long, but there is also a steady state error. Therefore, proportional gain and derivative gain need to be bigger to enhance settling time and the steady state error. The final controller yields the follwoing figures, where 30 degrees is the designated angle.
                            </p>
                            <img class="img-fluid" src="assets/img/lab6orientationYaw.jpg" alt="..." />
                            <img class="img-fluid" src="assets/img/lab6velocity.jpg" alt="..." />
                        </div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Wind-up implementation</h3>
                            <p>
                                The following code shows the wind-up implementation.
                            </p>
                            <pre>
                                <code>
                                    // I control
                                    integraterError += (errorCurrent*dt/10);
                                    if (integraterError > 8000){
                                      integraterError = 8000;
                                    }
                                    else if (integraterError < -8000){
                                      integraterError = -8000;
                                    }
                                    float I = ki*integraterError;
                                </code>
                            </pre>

                            <p>
                                The wind-up phenomenon happens when the integrator persistently accumulates errors, consequently extending the system's recovery duration. Despite the car's proximity to the target, the accumulated error remains unresolved, thereby exerting excessive force as the integrator continues to operate at full capacity. Setting a wind-up protection is to cap the maximum and minimum integrator error allowed to address this issue. 
                            </p>
                        </div>
                    </div>
                </div>
            </section>








            <hr class="m-0" />
            <!-- Interests-->
            <section class="resume-section" id="interests">
                <div class="resume-section-content">
                    <h2 class="mb-5">Interests</h2>
                    <p>Apart from being a web developer, I enjoy most of my time being outdoors. In the winter, I am an avid skier and novice ice climber. During the warmer months here in Colorado, I enjoy mountain biking, free climbing, and kayaking.</p>
                    <p class="mb-0">When forced indoors, I follow a number of sci-fi and fantasy genre movies and television shows, I am an aspiring chef, and I spend a large amount of my free time exploring the latest technology advancements in the front-end web development world.</p>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Awards-->
            <section class="resume-section" id="awards">
                <div class="resume-section-content">
                    <h2 class="mb-5">Awards & Certifications</h2>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            Google Analytics Certified Developer
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            Mobile Web Specialist - Google Certification
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            1
                            <sup>st</sup>
                            Place - University of Colorado Boulder - Emerging Tech Competition 2009
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            1
                            <sup>st</sup>
                            Place - University of Colorado Boulder - Adobe Creative Jam 2008 (UI Design Category)
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            2
                            <sup>nd</sup>
                            Place - University of Colorado Boulder - Emerging Tech Competition 2008
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            1
                            <sup>st</sup>
                            Place - James Buchanan High School - Hackathon 2006
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            3
                            <sup>rd</sup>
                            Place - James Buchanan High School - Hackathon 2005
                        </li>
                    </ul>
                </div>
            </section>
        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
